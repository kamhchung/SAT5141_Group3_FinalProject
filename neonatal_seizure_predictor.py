# -*- coding: utf-8 -*-
"""Neonatal_Seizure_Predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IouUIoseS1wjiKdCcBH52520FiCs7Wpe
"""

#Import required packages

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from imblearn.over_sampling import RandomOverSampler, SMOTE
from sklearn.model_selection import GroupShuffleSplit
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score )


import ipywidgets as widgets
from IPython.display import display, clear_output

#Dataset of neonatal EEG graded for severity of background abnormalities in HIE
metadata_url = "https://zenodo.org/records/7477575/files/metadata.csv?download=1"

meta_df = pd.read_csv(metadata_url)
print("Metadata shape:", meta_df.shape)
meta_df.head()

#Clean and convert seizures_YN column to binary

#Convert seizures_YN from 'Y'/'N' to 1/0
meta_df['seizure_label'] = meta_df['seizures_YN'].map({'Y': 1, 'N': 0})

print(meta_df['seizure_label'].value_counts(dropna=False))

#Convert grade to numeric (should be 1–4)
meta_df['grade'] = pd.to_numeric(meta_df['grade'], errors='coerce')
meta_df['sampling_freq'] = pd.to_numeric(meta_df['sampling_freq'], errors='coerce')

meta_df[['grade', 'sampling_freq', 'seizure_label']].describe()

#Define features (X) and target (y)

#Length of EEG_quality_comment
meta_df['comment_length'] = meta_df['EEG_quality_comment'].astype(str).str.len()

feature_cols_numeric = ['grade', 'sampling_freq', 'epoch_number', 'comment_length']
feature_cols_categorical = ['reference']

#Drop rows with missing critical values
model_df = meta_df.dropna(subset=feature_cols_numeric + ['seizure_label'])

X = model_df[feature_cols_numeric + feature_cols_categorical]
y = model_df['seizure_label']

# Train/test split manually due to imbalanced dataset
# 1 seizure baby train, 1 seizure baby test because there are only 2 in the entire dataset

seizure_babies = model_df.loc[model_df["seizure_label"] == 1, "baby_ID"].unique()
nonseizure_babies = model_df.loc[model_df["seizure_label"] == 0, "baby_ID"].unique()

print("\nBabies with seizures:", seizure_babies)
print("Babies without seizures:", len(nonseizure_babies))

np.random.seed(42)
seizure_babies = np.random.permutation(seizure_babies)
nonseizure_babies = np.random.permutation(nonseizure_babies)

#Use one seizure case for each set
test_seizure_babies = seizure_babies[:1]
train_seizure_babies = seizure_babies[1:]

#Use 20% of non-seizure babies for testing
n_nonseiz_test = max(1, int(0.2 * len(nonseizure_babies)))
test_nonseizure_babies = nonseizure_babies[:n_nonseiz_test]
train_nonseizure_babies = nonseizure_babies[n_nonseiz_test:]

test_babies = list(test_seizure_babies) + list(test_nonseizure_babies)
train_babies = list(train_seizure_babies) + list(train_nonseizure_babies)


train_mask = model_df["baby_ID"].isin(train_babies)
test_mask = model_df["baby_ID"].isin(test_babies)

X_train = X[train_mask]
y_train = y[train_mask]
X_test = X[test_mask]
y_test = y[test_mask]

print("\nClass distribution in TRAIN:")
print(y_train.value_counts())
print("\nClass distribution in TEST:")
print(y_test.value_counts())

#Oversample minority class in train only because of the imbalance of present vs absent seizures
ros = RandomOverSampler(random_state=42)
X_train_res, y_train_res = ros.fit_resample(X_train, y_train)

print("\nOriginal TRAIN counts:")
print(y_train.value_counts())
print("\nResampled TRAIN counts:")
print(y_train_res.value_counts())

#Build logistic regression model
numeric_features = feature_cols_numeric
categorical_features = feature_cols_categorical

numeric_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')

preprocess = ColumnTransformer(
    transformers=[('num', numeric_transformer, numeric_features), ('cat', categorical_transformer, categorical_features)])

log_reg = LogisticRegression(
    max_iter=1000,
    class_weight=None,  #already oversampling
    n_jobs=-1,
    random_state=42)

clf = Pipeline(steps=[
    ('preprocess', preprocess),
    ('model', log_reg)])

clf.fit(X_train_res, y_train_res)

#Evaluate at default threshold
y_prob = clf.predict_proba(X_test)[:, 1]
y_pred_default = (y_prob >= 0.5).astype(int)

print("\n=== Classification Report: Logistic Regression (threshold = 0.50) ===")
print(classification_report(y_test, y_pred_default, digits=3, zero_division=0))

cm_default = confusion_matrix(y_test, y_pred_default)

plt.figure(figsize=(5, 4))
sns.heatmap(cm_default, annot=True, fmt="d", cbar=False)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Logistic Regression – Confusion Matrix (threshold = 0.50)")
plt.show()

auc_default = roc_auc_score(y_test, y_prob)
print(f"ROC-AUC: {auc_default:.3f}")

#Evaluate model to prioritize reducing false negatives
thresholds = np.linspace(0, 1, 101)
sensitivities = []

for t in thresholds:
    y_pred_t = (y_prob >= t).astype(int)
    sens = recall_score(y_test, y_pred_t, zero_division=0)
    sensitivities.append(sens)

plt.figure(figsize=(7, 5))
plt.plot(thresholds, sensitivities, label="Sensitivity (Recall)")
plt.xlabel("Threshold")
plt.ylabel("Sensitivity")
plt.title("Sensitivity vs Classification Threshold")
plt.grid(True)
plt.legend()
plt.show()

#Choose high-sensitivity operating point
desired_recall = 0.90
opt_thresh = None

for t, sens in zip(thresholds, sensitivities):
    y_pred_t = (y_prob >= t).astype(int)
    #Ensure at least one predicted seizure at this threshold
    if (y_pred_t == 1).sum() == 0:
        continue
    if sens >= desired_recall:
        opt_thresh = t
        break

if opt_thresh is None:
    #If 90% recall not achievable, use best threshold that predicts ≥1 seizure
    best_idx = 0
    best_sens = -1
    for i, t in enumerate(thresholds):
        y_pred_t = (y_prob >= t).astype(int)
        if (y_pred_t == 1).sum() == 0:
            continue
        sens = sensitivities[i]
        if sens > best_sens:
            best_sens = sens
            best_idx = i
    opt_thresh = thresholds[best_idx]
    print(f"\nCould not reach {desired_recall:1%} recall; "
          f"using threshold {opt_thresh:.2f} with sensitivity = {best_sens:.2f}")

print(f"\nChosen operating threshold: {opt_thresh:.2f}")

y_pred_opt = (y_prob >= opt_thresh).astype(int)

#Classification report for high sensitivity threshold
print("\n=== Classification Report @ high-sensitivity threshold ===")
print(classification_report(y_test, y_pred_opt, digits=3, zero_division=0))

cm_opt = confusion_matrix(y_test, y_pred_opt)

plt.figure(figsize=(5, 4))
sns.heatmap(cm_opt, annot=True, fmt="d", cbar=False)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title(f"Logistic Regression – Confusion Matrix (threshold = {opt_thresh:.2f})")
plt.show()

print(f"ROC-AUC (unchanged): {auc_default:.3f}")

#Load clinical_information.csv dataset

#Dataset of neonatal EEG recordings with seizure annotations
clinical_url = "https://zenodo.org/records/2547147/files/clinical_information.csv?download=1"

clinical_df = pd.read_csv(clinical_url)
print("Clinical data shape:", clinical_df.shape)
clinical_df.head()

#Create binary seizure label from reviewers, 1 if any seizures, 0 if none
clinical_df["seizure_label"] = (clinical_df["Number of Reviewers Annotating Seizure"] > 0).astype(int)

print("Class counts (0 = no seizure, 1 = seizure):")
print(clinical_df["seizure_label"].value_counts())

#Select predictors and drop ID-like columns

#Columns NOT to be used
drop_cols = ["ID", "EEG file", "Number of Reviewers Annotating Seizure", "Primary Localisation", "Other"]

#Drop columns that actually exist in the dataframe
model_df = clinical_df.drop(columns=[c for c in drop_cols if c in clinical_df.columns])

#Separate X (features) and y (label)
X = model_df.drop(columns=["seizure_label"])
y = model_df["seizure_label"]

print("X shape before encoding:", X.shape)
print("y shape:", y.shape)

#Use one-hot encoding on the categorical columns
categorical_cols = ["Gender", "BW (g)", "GA (weeks)", "EEG to PMA (weeks)", "Diagnosis", "Neuroimaging Findings", "PNA of Imaging (days)"]

#Only encode the ones that are actually present in X
categorical_cols = [c for c in categorical_cols if c in X.columns]

X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

#Fill any remaining NaNs with median of each column
X_encoded = X_encoded.fillna(X_encoded.median())

print("X shape after encoding:", X_encoded.shape)
X_encoded.head()

#Train / test split and scaling
X_train, X_test, y_train, y_test = train_test_split(
    X_encoded,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("Train size:", X_train_scaled.shape[0])
print("Test size:", X_test_scaled.shape[0])

#Logistic Regression model

log_reg = LogisticRegression(
    max_iter=1000,
    class_weight="balanced",
    n_jobs=-1)

log_reg.fit(X_train_scaled, y_train)

y_pred = log_reg.predict(X_test_scaled)
y_prob = log_reg.predict_proba(X_test_scaled)[:, 1]

print("=== Classification Report: Clinical Seizure Model ===")
print(classification_report(y_test, y_pred, digits=3))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt='d', cbar=False)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix – Clinical Seizure Model")
plt.show()

auc = roc_auc_score(y_test, y_prob)
print(f"ROC-AUC: {auc:.3f}")

#Decide which clinical factors are significant
feature_names = X_encoded.columns
coeffs = log_reg.coef_[0]

importance_df = pd.DataFrame({
    "feature": feature_names,
    "coefficient": coeffs,
    "abs_coeff": np.abs(coeffs)
}).sort_values("abs_coeff", ascending=False)

#Visualize clinicically important features
plt.figure(figsize=(8, 6))
top_n = 15
sns.barplot(
    data=importance_df.head(top_n),
    x="abs_coeff",
    y="feature")
plt.title(f"Top {top_n} Clinical Features by |Coefficient|")
plt.xlabel("Importance (|coef|)")
plt.ylabel("Feature")
plt.tight_layout()
plt.show()

#Sarnat score calculator

#Define dropdown options
sarnat_dropdowns = {
    "Level of consciousness": [
        ("Normal (0) – Awake or appropriately responsive", 0),
        ("Mild (1) – Hyperalert, irritable, jittery", 1),
        ("Moderate (2) – Lethargic, poorly responsive", 2),
        ("Severe (3) – Comatose or minimally responsive", 3),],
    "Spontaneous activity": [
        ("Normal (0) – Normal spontaneous movement", 0),
        ("Mild (1) – Slightly decreased movement", 1),
        ("Moderate (2) – Markedly decreased movement", 2),
        ("Severe (3) – No spontaneous movement", 3),],
    "Posture": [
        ("Normal (0) – Normal newborn flexed posture", 0),
        ("Mild (1) – Mild distal flexion", 1),
        ("Moderate (2) – Complete extension / decreased flexion", 2),
        ("Severe (3) – Decerebrate / rigid extension", 3),],
    "Muscle tone": [
        ("Normal (0) – Normal tone", 0),
        ("Mild (1) – Hypertonic / increased tone", 1),
        ("Moderate (2) – Hypotonic / decreased tone", 2),
        ("Severe (3) – Flaccid / no tone", 3),],
    "Primitive reflexes (suck/Moro)": [
        ("Normal (0) – Strong suck and complete Moro", 0),
        ("Mild (1) – Low-threshold, exaggerated Moro", 1),
        ("Moderate (2) – Weak or incomplete Moro / weak suck", 2),
        ("Severe (3) – Absent Moro and absent suck", 3),],
    "Autonomic reflexes (pupils/breathing)": [
        ("Normal (0) – Normal pupils & breathing pattern", 0),
        ("Mild (1) – Mild abnormalities, usually normal", 1),
        ("Moderate (2) – Constricted pupils OR periodic breathing", 2),
        ("Severe (3) – Dilated non-reactive pupils OR ventilated", 3),],}

#Develop sarnat score function

def calculate_sarnat_scores(selections):
    total = sum(selections.values())

    if total <= 6:
        stage = "Stage I (Mild HIE)"
        interp = "Findings in mild range. Recommend observation and repeated neuro exams."
        eeg_recommendation = (
            "EEG: Routine EEG or amplitude-integrated EEG may be considered if there are "
            "concerning features (abnormal movements, apnea spells, or change in exam), "
            "but continuous EEG is not universally required at this stage.")
    elif total <= 12:
        stage = "Stage II (Moderate HIE)"
        interp = ("Findings consistent with moderate HIE. This is typically the group "
                  "in which therapeutic hypothermia is considered alongside clinical criteria.")
        eeg_recommendation = (
            "EEG: Continuous EEG or aEEG monitoring is recommended to detect subclinical "
            "seizures and monitor background changes during hypothermia and rewarming.")
    else:
        stage = "Stage III (Severe HIE)"
        interp = ("Severe encephalopathy with high risk for seizures and brain injury. "
                  "Requires intensive monitoring and support.")
        eeg_recommendation = (
            "EEG: Urgent continuous EEG monitoring is strongly recommended to detect "
            "frequent subclinical seizures and assess background suppression.")

    return total, stage, interp, eeg_recommendation

#Develop interactive scoring tool
def sarnat_score_widget():
    dropdown_widgets = {}

    #Create dropdown options for each category
    for category, options in sarnat_dropdowns.items():
        dropdown_widgets[category] = widgets.Dropdown(
            options=options,
            description=category,
            style={"description_width": "initial"},
            layout=widgets.Layout(width="600px"))

    calc_button = widgets.Button(
        description="Calculate Sarnat Score",
        button_style="primary",
        layout=widgets.Layout(width="250px"))

    output = widgets.Output()

    #Program buttons
    def on_click(b):
        with output:
            clear_output()

            numeric_scores = {cat: dropdown_widgets[cat].value for cat in dropdown_widgets}
            total, stage, interp, eeg_reco = calculate_sarnat_scores(numeric_scores)

            print("=== Modified Sarnat Score (Educational Prototype) ===\n")
            for cat, score in numeric_scores.items():
                print(f"{cat}: {score}")
            print(f"\nTOTAL SCORE: {total} / 18")
            print(f"Stage: {stage}")
            print("\nInterpretation:")
            print(interp)
            print("\nEEG Recommendation (for educational use only):")
            print(eeg_reco)
            print("\nNote: This tool is for educational purposes only and is not a "
                  "validated clinical decision support system.")

    calc_button.on_click(on_click)

    display(widgets.VBox([
        widgets.HTML("<h3>Enhanced Modified Sarnat Score Calculator</h3>"
                     "<p>Select the clinical findings for each category.</p>"),
        *dropdown_widgets.values(),
        calc_button,
        output
    ]))

#deploy widget
sarnat_score_widget()
